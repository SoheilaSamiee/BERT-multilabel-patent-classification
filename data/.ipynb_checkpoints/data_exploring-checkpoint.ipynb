{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "no element found: line 1, column 0 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/mila/s/samieeso/.conda/envs/CondaEnv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3343\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-11-cfedbb1cd698>\"\u001b[0m, line \u001b[1;32m2\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    tree = ET.parse('ipg210105_2.xml')\n",
      "  File \u001b[1;32m\"/home/mila/s/samieeso/.conda/envs/CondaEnv/lib/python3.6/xml/etree/ElementTree.py\"\u001b[0m, line \u001b[1;32m1196\u001b[0m, in \u001b[1;35mparse\u001b[0m\n    tree.parse(source, parser)\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/mila/s/samieeso/.conda/envs/CondaEnv/lib/python3.6/xml/etree/ElementTree.py\"\u001b[0;36m, line \u001b[0;32m597\u001b[0;36m, in \u001b[0;35mparse\u001b[0;36m\u001b[0m\n\u001b[0;31m    self._root = parser._parse_whole(source)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mParseError\u001b[0m\u001b[0;31m:\u001b[0m no element found: line 1, column 0\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('ipg210105_2.xml')\n",
    "root = tree.getroot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MYFILE = 'ipg210105_2.xml'\n",
    "from lxml import etree\n",
    "context = etree.iterparse( MYFILE, tag='us-patent-grant' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "XMLSyntaxError",
     "evalue": "no element found (line 0)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/mila/s/samieeso/.conda/envs/CondaEnv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3343\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-16-c2b692205312>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    for event, element in context :\n",
      "  File \u001b[1;32m\"src/lxml/iterparse.pxi\"\u001b[0m, line \u001b[1;32m209\u001b[0m, in \u001b[1;35mlxml.etree.iterparse.__next__\u001b[0m\n",
      "  File \u001b[1;32m\"src/lxml/iterparse.pxi\"\u001b[0m, line \u001b[1;32m194\u001b[0m, in \u001b[1;35mlxml.etree.iterparse.__next__\u001b[0m\n",
      "  File \u001b[1;32m\"src/lxml/iterparse.pxi\"\u001b[0m, line \u001b[1;32m225\u001b[0m, in \u001b[1;35mlxml.etree.iterparse._read_more_events\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"src/lxml/parser.pxi\"\u001b[0;36m, line \u001b[0;32m1400\u001b[0;36m, in \u001b[0;35mlxml.etree._FeedParser.close\u001b[0;36m\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"ipg210105_2.xml\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mXMLSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m no element found\n"
     ]
    }
   ],
   "source": [
    "for event, element in context:\n",
    "    if element.tag == 'classifications-ipcr'\n",
    "    print(element)\n",
    "#    if element == 'classification-ipcr':\n",
    "#        print element.xpath('title()')\n",
    "    \n",
    "      #print element.xpath( 'description/text( )' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "zf = zipfile.ZipFile('ipg210105.zip', 'r')\n",
    "for name in zf.namelist():\n",
    "    f = zf.open(name)\n",
    "\n",
    "import lxml.etree as ET\n",
    "tree = ET.iterparse(f, events=('start', 'end'),tag=('classification-ipcr'))\n",
    "\n",
    "context = iter(tree)\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-66-7935c56264ae>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-66-7935c56264ae>\"\u001b[0;36m, line \u001b[0;32m17\u001b[0m\n\u001b[0;31m    if elem.'classification-locarno' is not None:\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "zf = zipfile.ZipFile('ipg210105.zip', 'r')\n",
    "for name in zf.namelist():\n",
    "    f = zf.open(name)\n",
    "\n",
    "#f = open('ipg210105_2.xml')\n",
    "level = 0\n",
    "for event, elem in ET.iterparse(f, events=('start', 'end')):\n",
    "    if event == 'start':\n",
    "       level +=1\n",
    "       if level ==3:\n",
    "           #print(level)\n",
    "           print(elem.tag) # use only tag name and attributes here\n",
    "    elif event == 'end':\n",
    "       level -=1\n",
    "       if level ==3:\n",
    "       # elem children elements, elem.text, elem.tail are available\n",
    "       if elem.'classification-locarno' is not None:\n",
    "          print('done!')\n",
    "          #print(repr(elem.section))\n",
    "        \n",
    "        \n",
    "#tree = ET.iterparse(f, events=(\"end\",))\n",
    "#context = iter(tree)\n",
    "\n",
    "event, root = next(context)\n",
    "root.attrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "XMLSyntaxError",
     "evalue": "Document is empty, line 1, column 1 (ipg210105.xml, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/mila/s/samieeso/.conda/envs/CondaEnv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3343\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-48-040f912a1ab0>\"\u001b[0m, line \u001b[1;32m4\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    for event, elem in ET.iterparse(f, events=(\"start\", \"end\")):\n",
      "  File \u001b[1;32m\"src/lxml/iterparse.pxi\"\u001b[0m, line \u001b[1;32m209\u001b[0m, in \u001b[1;35mlxml.etree.iterparse.__next__\u001b[0m\n",
      "  File \u001b[1;32m\"src/lxml/iterparse.pxi\"\u001b[0m, line \u001b[1;32m194\u001b[0m, in \u001b[1;35mlxml.etree.iterparse.__next__\u001b[0m\n",
      "  File \u001b[1;32m\"src/lxml/iterparse.pxi\"\u001b[0m, line \u001b[1;32m229\u001b[0m, in \u001b[1;35mlxml.etree.iterparse._read_more_events\u001b[0m\n",
      "  File \u001b[1;32m\"src/lxml/parser.pxi\"\u001b[0m, line \u001b[1;32m1384\u001b[0m, in \u001b[1;35mlxml.etree._FeedParser.feed\u001b[0m\n",
      "  File \u001b[1;32m\"src/lxml/parser.pxi\"\u001b[0m, line \u001b[1;32m606\u001b[0m, in \u001b[1;35mlxml.etree._ParserContext._handleParseResult\u001b[0m\n",
      "  File \u001b[1;32m\"src/lxml/parser.pxi\"\u001b[0m, line \u001b[1;32m615\u001b[0m, in \u001b[1;35mlxml.etree._ParserContext._handleParseResultDoc\u001b[0m\n",
      "  File \u001b[1;32m\"src/lxml/parser.pxi\"\u001b[0m, line \u001b[1;32m725\u001b[0m, in \u001b[1;35mlxml.etree._handleParseResult\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"src/lxml/parser.pxi\"\u001b[0;36m, line \u001b[0;32m654\u001b[0;36m, in \u001b[0;35mlxml.etree._raiseParseError\u001b[0;36m\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/mila/s/samieeso/python_projects/Patent_Classification/data/ipg210105.xml\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mXMLSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Document is empty, line 1, column 1\n"
     ]
    }
   ],
   "source": [
    "    #sys.stdout.flush()\n",
    "    level = 0\n",
    "    sim_list = []\n",
    "    for event, elem in ET.iterparse(f, events=(\"start\", \"end\")):\n",
    "        if event == \"start\":\n",
    "            level += 1\n",
    "            print(level)\n",
    "            print(elem.tag)\n",
    "        if event == \"end\":\n",
    "            level -= 1\n",
    "            if level == 2 and elem.tag == 'classification-ipcr':\n",
    "                #sim = Simulation(elem)\n",
    "                #sim_list.append(sim)\n",
    "                elem.clear() # won't need this any more\n",
    "                #sys.stdout.write(\".\")\n",
    "                #sys.stdout.flush()\n",
    "    print(\" done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<lxml.etree.iterparse object at 0x7f0e79620f28>\n",
      "<lxml.etree.iterparse object at 0x7f0e79620f28>\n"
     ]
    }
   ],
   "source": [
    "print(context)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "File_Name = ipg210105.xml\n",
    "File_object = open(r\"File_Name\",\"r\")\n",
    "\n",
    "File_object.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "a = pd.DataFrame()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start ...\n",
      "Filename: ipg210105_3.xml\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "1\n",
      "No Patent\n",
      "2\n",
      "No classification!\n",
      "3\n",
      "Start Parsing: \n",
      " \n",
      "\n",
      "{'A': True}\n",
      "['A']\n",
      "Finish parsing. \n",
      "\n",
      "4\n",
      "Start Parsing: \n",
      " \n",
      "\n",
      "{'A': True}\n",
      "['A']\n",
      "Finish parsing. \n",
      "\n",
      "5\n",
      "Start Parsing: \n",
      " \n",
      "\n",
      "{'A': True}\n",
      "['A']\n",
      "Finish parsing. \n",
      "\n",
      "Success Count: 3\n",
      "Error Count: 0\n",
      "Saved to file!\n"
     ]
    }
   ],
   "source": [
    "# Inspired by https://github.com/lettergram/parse-uspto-xml\n",
    "import pprint\n",
    "import os\n",
    "import sys\n",
    "import html\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Function \n",
    "# ---------------------------------------------------------------------------\n",
    "def parse_patent(bs):\n",
    "    \"\"\"\n",
    "    Parses a US patent in a BeautifulSoup object.\n",
    "    Only keeping the elements useful for our next text classification task\n",
    "    \"\"\"\n",
    "    \n",
    "    publication_title = bs.find('invention-title').text\n",
    "    application_type = bs.find('application-reference')['appl-type']\n",
    "\n",
    "    # International Patent Classification (IPC) Docs:\n",
    "    sections = {}\n",
    "    for classes in bs.find_all('classifications-ipcr'):\n",
    "        for el in classes.find_all('classification-ipcr'):\n",
    "            section = el.find('section').text                            \n",
    "            sections[section] = True\n",
    "    print(sections)\n",
    "    print(list(sections.keys()))\n",
    "        \n",
    "    regex = re.compile('[^a-zA-Z0-9]')  # remove all but alphabetic (even numbers -- change to '[^a-zA-Z0-9]' to keep numbers)\n",
    "        \n",
    "    abstracts = ''\n",
    "    for el in bs.find_all('abstract'):\n",
    "        abstracts += el.text.strip('\\n')\n",
    "        abstracts = regex.sub(' ', abstracts)\n",
    "        abstracts = re.sub(r'\\b\\w{1,2}\\b', '', abstracts)  # remove words of length < 3\n",
    "\n",
    "    \n",
    "    descriptions = ''\n",
    "    for el in bs.find_all('description'):\n",
    "        descriptions += el.text.strip('\\n')\n",
    "        descriptions = regex.sub(' ', descriptions)\n",
    "    \n",
    "    \n",
    "    claims = ''\n",
    "    for el in bs.find_all('claim'):\n",
    "        claims += el.text.strip('\\n')\n",
    "        claims = regex.sub(' ', claims)\n",
    "    \n",
    "    \n",
    "    #labels = list(sections.keys())\n",
    "    #id_change ={\"A\":0, \"B\":1, \"C\":2, \"D\":3, \"E\":4, \"F\":5, \"G\":6, \"H\":7}\n",
    "    #labels_list = np.zeros((1,8),)\n",
    "    #labels_list(id_change[x])=1\n",
    "    \n",
    "    uspto_patent = {\n",
    "        \"sections\": list(sections.keys()),\n",
    "        \"publication_title\": regex.sub(' ', publication_title.replace(\"\\n\",\" \")),\n",
    "        \"application_type\": regex.sub(' ', application_type.replace(\"\\n\",\" \")),\n",
    "        \"abstract\": abstracts.replace(\"\\n\",\" \"), \n",
    "        \"descriptions\": descriptions.replace(\"\\n\",\" \"), \n",
    "        \"claims\": claims.replace(\"\\n\",\" \")\n",
    "    }        \n",
    "\n",
    "#    full_patent = {\n",
    "#        \"labels\": list(sections.keys()),\n",
    "#        \"text\": publication_title.replace(\"\\n\",\" \") + application_type.replace(\"\\n\",\" \") + abstracts.replace(\"\\n\",\" \") + descriptions.replace(\"\\n\",\" \") + claims.replace(\"\\n\",\" \")        \n",
    "#    }        \n",
    "\n",
    "    title_claims_patent =  {\n",
    "        \"labels\": list(sections.keys()),\n",
    "        \"text\": publication_title.replace(\"\\n\",\" \") + claims.replace(\"\\n\",\" \")        \n",
    "    }        \n",
    "    \n",
    "    title_abstract_patent =  {\n",
    "        \"labels\": list(sections.keys()),\n",
    "        \"text\": publication_title.replace(\"\\n\",\" \") + abstracts.replace(\"\\n\",\" \")        \n",
    "    }        \n",
    "    \n",
    "    return uspto_patent#, title_claims_patent,   title_abstract_patent \n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "filenames = 'ipg210105_3.xml'\n",
    "\n",
    "print('Start ...')    \n",
    "all_patents = pd.DataFrame()\n",
    "#column_names = [\"sections\",\"publication_title\", \"application_type\", \"abstract\",\"descriptions\",\"claims\"]\n",
    "#all_patents = pd.DataFrame(columns = column_names)\n",
    "n_file = 1\n",
    "count = 1\n",
    "success_count = 0\n",
    "errors = []\n",
    "\n",
    "print(\"Filename:\", filenames)\n",
    "print(\"\\n--------------------------------------------------------\\n\")\n",
    "\n",
    "xml_text = html.unescape(open(filenames, 'r').read())\n",
    "\n",
    "for patent in xml_text.split(\"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\"):\n",
    "    print(n_file)\n",
    "    n_file +=1\n",
    "\n",
    "    #print(patent)\n",
    "    \n",
    "    if patent is None or patent == \"\":\n",
    "        print('No Patent')\n",
    "        continue\n",
    "\n",
    "    bs = BeautifulSoup(patent)\n",
    "\n",
    "    # Skip documents which do not have classification-ipcr\n",
    "    if bs.find('classification-ipcr') is None:\n",
    "        print('No classification!')\n",
    "        continue \n",
    "\n",
    "    application = bs.find('us-patent-application')\n",
    "    if application is None: # If no application, search for grant\n",
    "        application = bs.find('us-patent-grant')\n",
    "\n",
    "    # Setting the title\n",
    "    title = \"None\"\n",
    "    try:\n",
    "        title = application.find('invention-title').text\n",
    "    except Exception as e:          \n",
    "        print(\"Error\", count, e)\n",
    "\n",
    "    # parsing the patent and saving it in a database\n",
    "    print('Start Parsing: \\n \\n')\n",
    "    uspto_patent = parse_patent(application)       \n",
    "    print('Finish parsing. \\n')\n",
    "    #print(uspto_patent)\n",
    "    new_patent = pd.DataFrame.from_dict(data=uspto_patent)\n",
    "    \n",
    "    if all_patents.empty:\n",
    "        all_patents = new_patent\n",
    "    else:\n",
    "        frames = [all_patents, new_patent]\n",
    "        all_patents = pd.concat(frames)                \n",
    "    success_count += 1\n",
    "\n",
    "    if (success_count+len(errors)) % 50 == 0:\n",
    "        print(count, filename, title)\n",
    "        new_patent.describe()\n",
    "    count += 1\n",
    "\n",
    "#print(\"\\n\\nErrors\\n------------------------\\n\")\n",
    "#for e in errors:\n",
    "#    print(e)\n",
    "    \n",
    "print(\"Success Count:\", success_count)\n",
    "print(\"Error Count:\", len(errors))\n",
    "\n",
    "all_patents.to_csv('all_patents_ipg210105.tsv', index=False, sep=\"\\t\")\n",
    "all_patents.to_csv('all_patents_ipg210105_3.csv', index=False)\n",
    "\n",
    "print('Saved to file!')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start ...\n",
      "Filename: ipg210105.xml\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "50 l Methods for hybrid corn seed production\n",
      "50\n",
      "100 l Antimicrobial compositions containing alkylpyrazines and their uses\n",
      "100\n",
      "150 l Temperature-reading face shield\n",
      "150\n",
      "200 l Item of furniture and wall element for an item of furniture\n",
      "200\n",
      "250 l Cleaner and method for controlling cleaner\n",
      "250\n",
      "300 l Devices and systems for correcting errors in blood pressure measurements\n",
      "300\n",
      "350 l Systems and methods for monitoring the health of vehicle passengers using camera images\n",
      "350\n",
      "400 l Positioning tool for anastomosis\n",
      "400\n",
      "450 l Peri-vascular tissue ablation catheters\n",
      "450\n",
      "500 l Lifetime regenerative heart valve\n",
      "500\n",
      "550 l Evaluation method of wearing state of disposable diaper, evaluation system of wearing state of disposable diaper, and non-transitory computer-readable storage medium with a program for evaluating wearing state of disposable diaper\n",
      "550\n",
      "600 l Methods for treating eye disorders using ocular implants\n",
      "600\n",
      "650 l Fatty liver disease treatment using glucocorticoid and mineralocorticoid receptor antagonists\n",
      "650\n",
      "700 l Anti-CSPG4 reagents and methods of treating cancer\n",
      "700\n",
      "750 l Preparation of high purity collagen particles and uses thereof\n",
      "750\n",
      "800 l Portable infusion pump\n",
      "800\n",
      "850 l Adaptive cardiac resynchronization therapy\n",
      "850\n",
      "900 l Gait rehabilitation control system and method therefor\n",
      "900\n",
      "950 l Location-based achievements framework\n",
      "950\n",
      "1000 l Manufacturing method of granules and manufacturing apparatus thereof with ability to rock an agitating blade\n",
      "1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c05091975d79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Skip documents which do not have classification-ipcr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/CondaEnv/lib/python3.6/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m                 \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/CondaEnv/lib/python3.6/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m         \u001b[0;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/CondaEnv/lib/python3.6/site-packages/bs4/builder/_lxml.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParserError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._FeedParser.feed\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parser.pxi\u001b[0m in \u001b[0;36mlxml.etree._FeedParser.feed\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._TargetParserContext._handleParseResult\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/etree.pyx\u001b[0m in \u001b[0;36mlxml.etree._ExceptionContext._raise_if_stored\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/saxparser.pxi\u001b[0m in \u001b[0;36mlxml.etree._handleSaxEndNoNs\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msrc/lxml/parsertarget.pxi\u001b[0m in \u001b[0;36mlxml.etree._PythonSaxParserTarget._handleSaxEnd\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/CondaEnv/lib/python3.6/site-packages/bs4/builder/_lxml.py\u001b[0m in \u001b[0;36mend\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0mcompleted_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagStack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getNsTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/CondaEnv/lib/python3.6/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36mendData\u001b[0;34m(self, containerClass)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \"\"\"\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mcontainerClass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainerClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/CondaEnv/lib/python3.6/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36mstring_container\u001b[0;34m(self, base_class)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;31m# There may be a general override of NavigableString.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         container = self.element_classes.get(\n\u001b[0m\u001b[1;32m    483\u001b[0m             \u001b[0mcontainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Inspired by https://github.com/lettergram/parse-uspto-xml\n",
    "import pprint\n",
    "import os\n",
    "import sys\n",
    "import html\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "filenames = 'ipg210105.xml'\n",
    "\n",
    "print('Start ...')\n",
    "    \n",
    "all_patents = []\n",
    "#column_names = [\"sections\",\"publication_title\", \"application_type\", \"abstract\",\"descriptions\",\"claims\"]\n",
    "#all_patents = pd.DataFrame(columns = column_names)\n",
    "n_file = 0\n",
    "count = 1\n",
    "success_count = 0\n",
    "errors = []\n",
    "\n",
    "print(\"Filename:\", filenames)\n",
    "print(\"\\n--------------------------------------------------------\\n\")\n",
    "\n",
    "xml_text = html.unescape(open(filenames, 'r').read())\n",
    "\n",
    "for patent in xml_text.split(\"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\"):\n",
    "    #print(n_file)\n",
    "    #n_file +=1\n",
    "\n",
    "    if patent is None or patent == \"\":\n",
    "        continue\n",
    "\n",
    "    bs = BeautifulSoup(patent)\n",
    "\n",
    "    # Skip documents which do not have classification-ipcr\n",
    "    if bs.find('classification-ipcr') is None:\n",
    "        continue \n",
    "\n",
    "    application = bs.find('us-patent-application')\n",
    "    if application is None: # If no application, search for grant\n",
    "        application = bs.find('us-patent-grant')\n",
    "\n",
    "    # Setting the title\n",
    "    title = \"None\"\n",
    "    try:\n",
    "        title = application.find('invention-title').text\n",
    "    except Exception as e:          \n",
    "        print(\"Error\", count, e)\n",
    "\n",
    "    # parsing the patent and saving it in a database\n",
    "    try:\n",
    "        uspto_patent = parse_patent(application)                \n",
    "        new_patent = pd.DataFrame(data=uspto_patent)\n",
    "        if all_patents == []:\n",
    "            all_patents = new_patent\n",
    "        else:\n",
    "            frames = [all_patents, new_patent]\n",
    "            all_patents = pd.concat(frames)                \n",
    "        success_count += 1\n",
    "    except Exception as e:\n",
    "        exception_tuple = (count, title, e)\n",
    "        errors.append(exception_tuple)\n",
    "        #print(exception_tuple)\n",
    "\n",
    "    if (success_count+len(errors)) % 50 == 0:\n",
    "        print(count, filename, title)\n",
    "        new_patent.describe()\n",
    "    count += 1\n",
    "\n",
    "#print(\"\\n\\nErrors\\n------------------------\\n\")\n",
    "#for e in errors:\n",
    "#    print(e)\n",
    "    \n",
    "print(\"Success Count:\", success_count)\n",
    "print(\"Error Count:\", len(errors))\n",
    "\n",
    "all_patents.to_csv('all_patents_ipg210105.tsv', index=False, sep=\"\\t\")\n",
    "print('Saved to file!')\n",
    "\n",
    "\n",
    "\n",
    "# Function \n",
    "def parse_patent(bs):\n",
    "    \"\"\"\n",
    "    Parses a US patent in a BeautifulSoup object.\n",
    "    Only keeping the elements useful for our next text classification task\n",
    "    \"\"\"\n",
    "    \n",
    "    publication_title = bs.find('invention-title').text\n",
    "    application_type = bs.find('application-reference')['appl-type']\n",
    "\n",
    "    # International Patent Classification (IPC) Docs:\n",
    "    sections = {}\n",
    "    for classes in bs.find_all('classifications-ipcr'):\n",
    "        for el in classes.find_all('classification-ipcr'):\n",
    "            section = el.find('section').text                            \n",
    "            sections[section] = True\n",
    "            \n",
    "    abstracts = []\n",
    "    for el in bs.find_all('abstract'):\n",
    "        abstracts.append(el.text.strip('\\n'))\n",
    "    \n",
    "    descriptions = []\n",
    "    for el in bs.find_all('description'):\n",
    "        descriptions.append(el.text.strip('\\n'))\n",
    "        \n",
    "    claims = []\n",
    "    for el in bs.find_all('claim'):\n",
    "        claims.append(el.text.strip('\\n'))\n",
    "\n",
    "    uspto_patent = {\n",
    "        \"publication_title\": publication_title,\n",
    "        \"application_type\": application_type,\n",
    "        \"sections\": list(sections.keys()),\n",
    "        \"abstract\": abstracts, # list\n",
    "        \"descriptions\": descriptions, # list\n",
    "        \"claims\": claims # list\n",
    "    }        \n",
    "    \n",
    "    return uspto_patent    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CondaEnv_Soheila",
   "language": "python",
   "name": "condaenv_soheila"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
